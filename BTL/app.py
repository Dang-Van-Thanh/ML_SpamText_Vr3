# app.py
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import joblib
from collections import Counter
from sklearn import tree
from sklearn.metrics import roc_curve, auc
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# ======================
# Th√™m th∆∞ vi·ªán x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng
# ======================
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler

sns.set_style("whitegrid")

# ======================
# 1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
# ======================
def clean_text(s):
    if not isinstance(s, str):
        return ""
    s = s.lower()
    s = re.sub(r"http\S+|www\S+|https\S+", " ", s)     # URL
    s = re.sub(r"\S+@\S+", " ", s)                     # Email
    s = re.sub(r"\+?\d[\d\s\-]{5,}\d", " ", s)         # S·ªë ƒëi·ªán tho·∫°i
    s = re.sub(r"[^a-z0-9\s]", " ", s)                 # K√Ω t·ª± ƒë·∫∑c bi·ªát
    s = re.sub(r"\s+", " ", s).strip()
    return s

def load_and_prepare(path):
    df = pd.read_csv(path, encoding="utf-8")
    df['text'] = df['sms']  # ƒë·ªìng nh·∫•t c·ªôt d√πng cho pipeline
    df['text_clean'] = df['sms'].apply(clean_text)
    df['len_char'] = df['sms'].apply(lambda x: len(str(x)))
    df['len_word'] = df['sms'].apply(lambda x: len(str(x).split()))
    df['has_number'] = df['sms'].str.contains(r"\d").astype(int)
    df['has_special'] = df['sms'].str.contains(r"[^a-zA-Z0-9\s]").astype(int)
    return df

# ======================
# 2. EDA (hi·ªÉn th·ªã trong Streamlit)
# ======================
def exploratory_data_analysis_streamlit(df):
    # Ph√¢n b·ªë nh√£n
    label_counts = df['label'].value_counts().sort_index()
    label_percent = (label_counts / label_counts.sum() * 100).round(2)

    st.subheader("üìä Ph√¢n b·ªë nh√£n (Count & Percent)")
    label_df = pd.DataFrame({
        "Label": label_counts.index.astype(str),
        "Count": label_counts.values,
        "Percent (%)": label_percent.values
    }).set_index("Label")
    st.table(label_df)

    # Bi·ªÉu ƒë·ªì c·ªôt
    fig, ax = plt.subplots(figsize=(4,3))
    sns.barplot(x=label_counts.index.astype(str), y=label_counts.values, palette="viridis", ax=ax)
    ax.set_title("S·ªë l∆∞·ª£ng theo nh√£n")
    st.pyplot(fig)

    # Bi·ªÉu ƒë·ªì b√°nh
    fig2, ax2 = plt.subplots(figsize=(4,3))
    colors = ["#4CAF50", "#F44336"] if len(label_percent) == 2 else None
    ax2.pie(label_percent.values, labels=label_percent.index.astype(str),
            autopct='%1.1f%%', startangle=90, colors=colors)
    ax2.axis('equal')
    st.pyplot(fig2)

    # ƒê·ªô d√†i tin nh·∫Øn
    df['msg_len'] = df['text'].apply(len)
    st.subheader("üìà Ph√¢n ph·ªëi ƒë·ªô d√†i tin nh·∫Øn")
    fig3, ax3 = plt.subplots(figsize=(4,3))
    sns.histplot(df['msg_len'], bins=50, kde=True, ax=ax3)
    st.pyplot(fig3)

    # Boxplot
    st.subheader("üì¶ Boxplot ƒë·ªô d√†i theo nh√£n")
    fig4, ax4 = plt.subplots(figsize=(4,3))
    sns.boxplot(x='label', y='msg_len', data=df, palette="Set2", ax=ax4)
    st.pyplot(fig4)

    # Top t·ª´ ph·ªï bi·∫øn
    st.subheader("üî§ Top 20 t·ª´ ph·ªï bi·∫øn c·ªßa Ham (0) v√† Spam (1)")
    ham_words = " ".join(df[df['label'] == 0]['text_clean'].astype(str)).split()
    spam_words = " ".join(df[df['label'] == 1]['text_clean'].astype(str)).split()
    ham_counts = Counter(ham_words).most_common(20)
    spam_counts = Counter(spam_words).most_common(20)

    fig5, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,6))
    if ham_counts:
        words_ham, counts_ham = zip(*ham_counts)
        sns.barplot(x=list(counts_ham), y=list(words_ham), palette="Blues_r", ax=ax1)
        ax1.set_title("Top 20 t·ª´ - Ham (0)")
    if spam_counts:
        words_spam, counts_spam = zip(*spam_counts)
        sns.barplot(x=list(counts_spam), y=list(words_spam), palette="Reds_r", ax=ax2)
        ax2.set_title("Top 20 t·ª´ - Spam (1)")
    st.pyplot(fig5)

    # T·ª∑ l·ªá ch·ª©a s·ªë / k√Ω t·ª± ƒë·∫∑c bi·ªát
    st.subheader("üîé T·ª∑ l·ªá ch·ª©a s·ªë / k√Ω t·ª± ƒë·∫∑c bi·ªát theo nh√£n")
    st.write(df.groupby('label')[['has_number', 'has_special']].mean().round(4))

    # B√°o c√°o EDA ng·∫Øn
    st.subheader("üìë B√°o c√°o EDA t·ª± ƒë·ªông (t√≥m t·∫Øt)")
    report = []
    if label_percent.min() < 30:
        report.append("‚ö†Ô∏è D·ªØ li·ªáu b·ªã m·∫•t c√¢n b·∫±ng nh√£n, c√¢n nh·∫Øc oversampling/undersampling.")
    else:
        report.append("‚úÖ D·ªØ li·ªáu ph√¢n b·ªë kh√° c√¢n b·∫±ng.")
    report.append("üìà Tin nh·∫Øn th∆∞·ªùng ng·∫Øn (<200 k√Ω t·ª±).")
    report.append("üì¶ Spam c√≥ xu h∆∞·ªõng d√†i h∆°n ham.")
    report.append("üîé Spam ch·ª©a nhi·ªÅu s·ªë/k√Ω t·ª± ƒë·∫∑c bi·ªát h∆°n ham.")
    for r in report:
        st.markdown("- " + r)

# ======================
# 3. Hu·∫•n luy·ªán & ƒë√°nh gi√°
# ======================
def train_and_evaluate(models, X_train, X_test, y_train, y_test, balance_option=None):
    # X·ª≠ l√Ω m·∫•t c√¢n b·∫±ng
    if balance_option == "Oversampling":
        ros = RandomOverSampler(random_state=42)
        X_train, y_train = ros.fit_resample(X_train, y_train)
    elif balance_option == "Undersampling":
        rus = RandomUnderSampler(random_state=42)
        X_train, y_train = rus.fit_resample(X_train, y_train)
    elif balance_option == "SMOTE":
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)

    results = []
    cms = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        results.append({"M√¥ h√¨nh": name, "Accuracy": acc, "Precision": prec,
                        "Recall": rec, "F1-score": f1})
        cms[name] = confusion_matrix(y_test, y_pred)
    return pd.DataFrame(results), cms

# ======================
# Main pipeline
# ======================
file_path = "BTL/data/train.csv"#"E:/DangVanThanh/train.csv"
df = load_and_prepare(file_path)

# TF-IDF
tfidf = TfidfVectorizer(stop_words='english', min_df=2, max_df=0.9, ngram_range=(1,2))
X = tfidf.fit_transform(df['text_clean'])
y = df['label'].values

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

# Sidebar: ch·ªçn c√¢n b·∫±ng
st.sidebar.subheader("‚öñÔ∏è X·ª≠ l√Ω m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu")
balance_option = st.sidebar.selectbox(
    "Ch·ªçn ph∆∞∆°ng ph√°p:",
    ["SMOTE", "Kh√¥ng x·ª≠ l√Ω", "Oversampling", "Undersampling"],
    index=0  # üëâ m·∫∑c ƒë·ªãnh SMOTE
)
balance_option = None if balance_option == "Kh√¥ng x·ª≠ l√Ω" else balance_option

# Model list
models = {
    "KNN (k=5)": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),
    "Naive Bayes": MultinomialNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42)
}
results_df, cms = train_and_evaluate(models, X_train, X_test, y_train, y_test, balance_option)

# L∆∞u TF-IDF v√† best model
joblib.dump(tfidf, "tfidf_vectorizer.pkl")
best_model_name = results_df.sort_values(by="F1-score", ascending=False).iloc[0]["M√¥ h√¨nh"]
best_model = models[best_model_name]
joblib.dump(best_model, "best_model.pkl")

# ======================
# Streamlit UI: 3 tab
# ======================
st.set_page_config(page_title="Spam SMS Detector", layout="centered")
tab1, tab2, tab3 = st.tabs(["üìä Kh√°m ph√° d·ªØ li·ªáu", "ü§ñ K·∫øt qu·∫£ m√¥ h√¨nh", "üì© D·ª± ƒëo√°n Spam/Ham"])

with tab1:
    st.header("üìä Kh√°m ph√° d·ªØ li·ªáu (EDA)")
    exploratory_data_analysis_streamlit(df)

with tab2:
    st.header("ü§ñ K·∫øt qu·∫£ m√¥ h√¨nh")
    sorted_df = results_df.sort_values(by="F1-score", ascending=False).reset_index(drop=True)
    st.dataframe(sorted_df)

    for name, model in models.items():
        st.subheader(f"Confusion Matrix - {name}")
        cm = cms[name]
        fig_cm, ax_cm = plt.subplots(figsize=(4,3))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                    xticklabels=["Ham (0)", "Spam (1)"],
                    yticklabels=["Ham (0)", "Spam (1)"],
                    ax=ax_cm)
        st.pyplot(fig_cm)

        if name == "Decision Tree":
            st.subheader("üå≥ C√¢y quy·∫øt ƒë·ªãnh")
            fig_tree, ax_tree = plt.subplots(figsize=(12, 6))
            tree.plot_tree(model, filled=True,
                           class_names=["Ham", "Spam"],
                           max_depth=3, fontsize=8, ax=ax_tree)
            st.pyplot(fig_tree)

        if hasattr(model, "predict_proba"):
            y_score = model.predict_proba(X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test, y_score)
            roc_auc = auc(fpr, tpr)
            st.subheader(f"üìà ROC Curve - {name}")
            fig_roc, ax_roc = plt.subplots(figsize=(4,3))
            ax_roc.plot(fpr, tpr, color="darkorange", lw=2, label=f"AUC = {roc_auc:.2f}")
            ax_roc.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
            ax_roc.legend(loc="lower right")
            st.pyplot(fig_roc)

    # B√°o c√°o m√¥ h√¨nh t·ªët nh·∫•t
    best_model = sorted_df.iloc[0]
    best_name = best_model['M√¥ h√¨nh']
    best_clf = models[best_name]
    cm = cms[best_name]
    tn, fp, fn, tp = cm.ravel()
    roc_auc = None
    if hasattr(best_clf, "predict_proba"):
        y_score = best_clf.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_score)
        roc_auc = auc(fpr, tpr)
    report_data = {
        "M√¥ h√¨nh": [best_name],
        "Accuracy": [f"{best_model['Accuracy']:.2f}"],
        "Precision": [f"{best_model['Precision']:.2f}"],
        "Recall": [f"{best_model['Recall']:.2f}"],
        "F1-score": [f"{best_model['F1-score']:.2f}"],
        "TP": [tp], "TN": [tn], "FP": [fp], "FN": [fn],
        "ROC AUC": [f"{roc_auc:.2f}" if roc_auc else "N/A"]
    }
    st.subheader("üîé B√°o c√°o t·ª± ƒë·ªông - M√¥ h√¨nh t·ªët nh·∫•t")
    st.table(pd.DataFrame(report_data))

with tab3:
    st.header("üì© D·ª± ƒëo√°n Spam/Ham")
    tfidf = joblib.load("tfidf_vectorizer.pkl")
    model = joblib.load("best_model.pkl")
    sms = st.text_area("Nh·∫≠p tin nh·∫Øn:", height=150)
    if st.button("D·ª± ƒëo√°n"):
        if sms.strip() == "":
            st.warning("B·∫°n ch∆∞a nh·∫≠p tin nh·∫Øn!")
        else:
            sms_clean = clean_text(sms)
            X_new = tfidf.transform([sms_clean])
            y_pred = model.predict(X_new)[0]
            prob = None
            if hasattr(model, "predict_proba"):
                prob = model.predict_proba(X_new).max()
            if int(y_pred) == 1:
                st.error(f"üö® Spam ({prob*100:.2f}%)" if prob else "üö® Spam")
            else:
                st.success(f"‚úÖ Ham ({prob*100:.2f}%)" if prob else "‚úÖ Ham")
